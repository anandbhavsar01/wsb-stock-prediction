{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd0cc8b-aba0-4884-af5b-179326a34462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "!pip -q install transformers\n",
    "!pip -q install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c726ad9-5616-4feb-a896-830bd183368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "import regex \n",
    "import emoji \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "937026fa-f32d-4b9c-8907-4b7b26c9a2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0759be2-22b8-4eed-9498-9483ad1d1c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f04de7f-87ee-421f-be8d-aa2bf5722e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:  ['i', 'am', 'happy']\n",
      "Token IDs:  [1045, 2572, 3407]\n"
     ]
    }
   ],
   "source": [
    "print('Tokenized: ', tokenizer.tokenize(\"I am happy\"))\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"I am happy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09eeb14b-c261-4431-92af-10e15944a8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "#########\n",
    "#########    CODE TO CLEAN DATA\n",
    "#########\n",
    "################################################\n",
    "\n",
    "\n",
    "def get_words(post):\n",
    "    split_l = post.split(\" \")\n",
    "    tmp_list = ' '.join(split_l).split()\n",
    "    normd = [ww.lower() for ww in tmp_list]\n",
    "    return normd\n",
    "\n",
    "def make_lower(word):\n",
    "    return word.lower()\n",
    "\n",
    "def remove_links(post):\n",
    "    url_pattern = re.compile(r'https?//\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', post)\n",
    "    \n",
    "def remove_bad_chars(post):\n",
    "    other_chars = ['*', '[', ']', '; ',\":\",\"“\",\"“\",\"”\",\"-\",\"=\",\"|\",\"^\"] \n",
    "    for char in other_chars:\n",
    "        post = post.replace(char, '')\n",
    "    return post\n",
    "\n",
    "def train_test_split(df, frac=0.2):   \n",
    "    # get random sample \n",
    "    test = df.sample(frac=frac, axis=0)\n",
    "    # get everything but the test sample\n",
    "    train = df.drop(index=test.index)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def get_processed_data(data, as_list=False, split=0.10):\n",
    "    data.dropna(subset=['body'], inplace=True)\n",
    "    data=data.reset_index()\n",
    "    \n",
    "    # remove bad characters\n",
    "    data[\"body\"]=data[\"body\"].apply(remove_bad_chars)\n",
    "    data[\"title\"]=data[\"title\"].apply(remove_bad_chars)\n",
    "    \n",
    "    # remove all links present in a post title and body\n",
    "    data[\"body\"]=data[\"body\"].apply(remove_links)\n",
    "    data[\"title\"]=data[\"title\"].apply(remove_links)\n",
    "    \n",
    "    data[\"body\"]=data[\"body\"].apply(make_lower)\n",
    "    data[\"title\"]=data[\"title\"].apply(make_lower)\n",
    "    \n",
    "    # put posts into list of words\n",
    "    if as_list:\n",
    "        print(\"Converting string to list of strings\")\n",
    "        data[\"body\"]=data[\"body\"].apply(get_words)\n",
    "        data[\"title\"]=data[\"title\"].apply(get_words)\n",
    "    else:\n",
    "        data[\"body\"]=data[\"body\"].apply(make_lower)\n",
    "        data[\"title\"]=data[\"title\"].apply(make_lower)\n",
    "        \n",
    "    data_train, data_test = train_test_split(data,frac=split)\n",
    "\n",
    "        \n",
    "    return data_train, data_test, data\n",
    "\n",
    "def convert_to_dict(data,col):\n",
    "    my_dict = {}\n",
    "    for index, row in data.iterrows():\n",
    "        my_dict[index] = row[col]\n",
    "    return my_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c2040db-6e20-4461-a0c2-b28006805106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(input_file):\n",
    "    emoji_list = []\n",
    "    emoji_mat = {}\n",
    "    posts = input_file.readlines()\n",
    "    for line in posts:\n",
    "        post = line[0]\n",
    "        data = regex.findall(r'\\X', post)\n",
    "        for word in data:\n",
    "            if any(char in emoji.EMOJI_DATA for char in word):\n",
    "                if word not in emoji_list:\n",
    "                    emoji_list.append(word)\n",
    "    \n",
    "    for key in emoji_list:\n",
    "        emoji_mat[key] = np.zeros(len(posts)-1)\n",
    "\n",
    "    i = 0\n",
    "    for line in posts:\n",
    "        post = line[0]\n",
    "        data = regex.findall(r'\\X', post)\n",
    "        for word in data:\n",
    "            for char in word:\n",
    "                if emoji_mat.get(char) is not None:\n",
    "                    emoji_mat[char][i] += 1\n",
    "        i += 1\n",
    "    return emoji_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a1f4994-88cb-4541-9174-00c363f260cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprocessing code\n",
    "def preprocess(f_in,to_list=False):\n",
    "    #print(\"[preprocess::extract emojis]\")\n",
    "    #f = open(f_in, \"r\")\n",
    "    #my_dict_emoji = extract_emojis(f)\n",
    "\n",
    "    # open and process\n",
    "    print(\"[preprocess::extract titles and body]\")\n",
    "    data = pd.read_csv(f_in)\n",
    "    processed_train, processed_test, processed_all =get_processed_data(data,as_list=to_list)\n",
    "        \n",
    "    my_dict_titles_train = convert_to_dict(processed_train,\"title\")\n",
    "    my_dict_body_train = convert_to_dict(processed_train,\"body\")\n",
    "    \n",
    "    my_dict_titles_test = convert_to_dict(processed_test,\"title\")\n",
    "    my_dict_body_test = convert_to_dict(processed_test,\"body\")\n",
    "    \n",
    "    my_dict_titles_all = convert_to_dict(processed_all,\"title\")\n",
    "    \n",
    "    print(\"[preprocess::complete]\")\n",
    "    #return my_dict_emoji,my_dict_titles, my_dict_body, processed\n",
    "    return my_dict_titles_train, my_dict_body_train, processed_train, my_dict_titles_test, my_dict_body_test, processed_test, my_dict_titles_all, processed_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53033de2-d7bc-495b-bfc9-89730f85cd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess::extract titles and body]\n",
      "[preprocess::complete]\n"
     ]
    }
   ],
   "source": [
    "#######\n",
    "#######\n",
    "####### LOAD DATA HERE\n",
    "#######\n",
    "#######\n",
    "\n",
    "import pandas as pd\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "client = storage.Client()\n",
    "bucket_name = \"my_processed_data_bucket\"\n",
    "file_name = \"text_and_label.csv\"\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "blob = bucket.get_blob(file_name)\n",
    "content = blob.download_as_string()\n",
    "\n",
    "dict_titles_train, dict_body_train, processed_train, dict_titles_test, dict_body_test, processed_test, my_dict_titles_all, processed_all  = preprocess(BytesIO(content))\n",
    "vader_labels_train = list(processed_train[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9046042e-3aad-49e0-a90b-1258df668b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET THE LABELS FROM WORDS TO INTEGERS\n",
    "labels_train = []\n",
    "# likely need to change later?\n",
    "#  converts hold -> 0, sell -> 1, and buy -> 2\n",
    "for ll in vader_labels_train:\n",
    "    if ll == \"Neutral\":\n",
    "        labels_train.append(0)\n",
    "    elif ll == \"Positive\":\n",
    "        labels_train.append(1)\n",
    "    elif ll == \"Negative\":\n",
    "        labels_train.append(2)\n",
    "\n",
    "vader_labels_test = list(processed_test[\"label\"])\n",
    "labels_test = []\n",
    "for ll in vader_labels_test:\n",
    "    if ll == \"Neutral\":\n",
    "        labels_test.append(0)\n",
    "    elif ll == \"Positive\":\n",
    "        labels_test.append(1)\n",
    "    elif ll == \"Negative\":\n",
    "        labels_test.append(2)\n",
    "        \n",
    "labels_all = []\n",
    "vader_labels_all = list(processed_all[\"label\"])\n",
    "for ll in vader_labels_all:\n",
    "    if ll == \"Neutral\":\n",
    "        labels_all.append(0)\n",
    "    elif ll == \"Positive\":\n",
    "        labels_all.append(1)\n",
    "    elif ll == \"Negative\":\n",
    "        labels_all.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dbc6b27-6e6f-48c5-93c4-f6f49f928a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an open letter to melvin capital, cnbc, boomers, and wsb\n"
     ]
    }
   ],
   "source": [
    "# GET SENTENCES \n",
    "sentences_train = list(dict_titles_train.values())\n",
    "#print(sentences)\n",
    "#sentences = sentences[100:420]\n",
    "print(sentences_train[50])\n",
    "# make fake labels for now \n",
    "#labels = [1 for ss in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "747685eb-b903-4f4d-878d-60d5cc75d217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "#################\n",
    "#####\n",
    "#####    TRAINING DATA ONLY\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "sentences = sentences_train\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                        truncation=True\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels_train)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "#print('Original: ', sentences[0])\n",
    "#print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48bf4dd5-0119-4697-83f1-ec0c6fa1ee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20,037 training samples\n",
      "2,227 validation samples\n"
     ]
    }
   ],
   "source": [
    "# set up training and testing\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5a51374-e9a3-4f2c-bc2c-640c7d6c83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d903a93-d3bd-484f-8fec-58a1463d5650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1f171ec-933c-4677-9d2d-78ef34f25baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1195cc9-c140-42ac-aeab-05d7ffc80a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, setting notebook to 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b2fe8af-c5ef-457d-9a14-3b1790fd7403",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, at first but it takes about 18 minutes - so revised to 1 for analysis turn around.\n",
    "# Likely will settle on 2\n",
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e67d338-df7a-419a-8cc4-2421af5b41f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Set the batch size.  \\nbatch_size = 10\\n\\n# Create the DataLoader.\\nprediction_data = TensorDataset(input_ids, attention_masks, labels)\\nprediction_sampler = SequentialSampler(prediction_data)\\nprediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\\n\\nprint('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\\n\\n# Put model in evaluation mode\\nmodel.eval()\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "'''\n",
    "# Set the batch size.  \n",
    "batch_size = 10\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4778e98d-cdca-4231-b5de-f22cb0458084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11d50a0f-8946-4614-9e87-fc0d28896005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7bb9be1-e557-4a9c-b9fe-ad1998308f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  1,253.    Elapsed: 0:00:48.\n",
      "  Batch    80  of  1,253.    Elapsed: 0:01:21.\n",
      "  Batch   120  of  1,253.    Elapsed: 0:01:54.\n",
      "  Batch   160  of  1,253.    Elapsed: 0:02:27.\n",
      "  Batch   200  of  1,253.    Elapsed: 0:03:01.\n",
      "  Batch   240  of  1,253.    Elapsed: 0:03:34.\n",
      "  Batch   280  of  1,253.    Elapsed: 0:04:07.\n",
      "  Batch   320  of  1,253.    Elapsed: 0:04:40.\n",
      "  Batch   360  of  1,253.    Elapsed: 0:05:13.\n",
      "  Batch   400  of  1,253.    Elapsed: 0:05:46.\n",
      "  Batch   440  of  1,253.    Elapsed: 0:06:19.\n",
      "  Batch   480  of  1,253.    Elapsed: 0:06:53.\n",
      "  Batch   520  of  1,253.    Elapsed: 0:07:26.\n",
      "  Batch   560  of  1,253.    Elapsed: 0:07:59.\n",
      "  Batch   600  of  1,253.    Elapsed: 0:08:32.\n",
      "  Batch   640  of  1,253.    Elapsed: 0:09:05.\n",
      "  Batch   680  of  1,253.    Elapsed: 0:09:38.\n",
      "  Batch   720  of  1,253.    Elapsed: 0:10:12.\n",
      "  Batch   760  of  1,253.    Elapsed: 0:10:45.\n",
      "  Batch   800  of  1,253.    Elapsed: 0:11:18.\n",
      "  Batch   840  of  1,253.    Elapsed: 0:11:51.\n",
      "  Batch   880  of  1,253.    Elapsed: 0:12:24.\n",
      "  Batch   920  of  1,253.    Elapsed: 0:12:57.\n",
      "  Batch   960  of  1,253.    Elapsed: 0:13:31.\n",
      "  Batch 1,000  of  1,253.    Elapsed: 0:14:04.\n",
      "  Batch 1,040  of  1,253.    Elapsed: 0:14:37.\n",
      "  Batch 1,080  of  1,253.    Elapsed: 0:15:10.\n",
      "  Batch 1,120  of  1,253.    Elapsed: 0:15:43.\n",
      "  Batch 1,160  of  1,253.    Elapsed: 0:16:16.\n",
      "  Batch 1,200  of  1,253.    Elapsed: 0:16:50.\n",
      "  Batch 1,240  of  1,253.    Elapsed: 0:17:23.\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:17:33\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation Loss: 0.35\n",
      "  Validation took: 0:00:37\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  1,253.    Elapsed: 0:00:33.\n",
      "  Batch    80  of  1,253.    Elapsed: 0:01:06.\n",
      "  Batch   120  of  1,253.    Elapsed: 0:01:40.\n",
      "  Batch   160  of  1,253.    Elapsed: 0:02:13.\n",
      "  Batch   200  of  1,253.    Elapsed: 0:02:46.\n",
      "  Batch   240  of  1,253.    Elapsed: 0:03:19.\n",
      "  Batch   280  of  1,253.    Elapsed: 0:03:52.\n",
      "  Batch   320  of  1,253.    Elapsed: 0:04:26.\n",
      "  Batch   360  of  1,253.    Elapsed: 0:04:59.\n",
      "  Batch   400  of  1,253.    Elapsed: 0:05:32.\n",
      "  Batch   440  of  1,253.    Elapsed: 0:06:05.\n",
      "  Batch   480  of  1,253.    Elapsed: 0:06:38.\n",
      "  Batch   520  of  1,253.    Elapsed: 0:07:11.\n",
      "  Batch   560  of  1,253.    Elapsed: 0:07:45.\n",
      "  Batch   600  of  1,253.    Elapsed: 0:08:18.\n",
      "  Batch   640  of  1,253.    Elapsed: 0:08:51.\n",
      "  Batch   680  of  1,253.    Elapsed: 0:09:24.\n",
      "  Batch   720  of  1,253.    Elapsed: 0:09:57.\n",
      "  Batch   760  of  1,253.    Elapsed: 0:10:30.\n",
      "  Batch   800  of  1,253.    Elapsed: 0:11:03.\n",
      "  Batch   840  of  1,253.    Elapsed: 0:11:37.\n",
      "  Batch   880  of  1,253.    Elapsed: 0:12:10.\n",
      "  Batch   920  of  1,253.    Elapsed: 0:12:43.\n",
      "  Batch   960  of  1,253.    Elapsed: 0:13:16.\n",
      "  Batch 1,000  of  1,253.    Elapsed: 0:13:49.\n",
      "  Batch 1,040  of  1,253.    Elapsed: 0:14:22.\n",
      "  Batch 1,080  of  1,253.    Elapsed: 0:14:55.\n",
      "  Batch 1,120  of  1,253.    Elapsed: 0:15:29.\n",
      "  Batch 1,160  of  1,253.    Elapsed: 0:16:02.\n",
      "  Batch 1,200  of  1,253.    Elapsed: 0:16:35.\n",
      "  Batch 1,240  of  1,253.    Elapsed: 0:17:08.\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:17:18\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation Loss: 0.31\n",
      "  Validation took: 0:00:37\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:36:05 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "############################################\n",
    "############################################\n",
    "##\n",
    "##           TRAINING \n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            result = model(b_input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=b_input_mask,\n",
    "                           labels=b_labels,\n",
    "                           return_dict=True)\n",
    "\n",
    "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
    "        # output values prior to applying an activation function like the \n",
    "        # softmax.\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a62b934a-eb87-4702-9fa7-692ed642a630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0:17:33</td>\n",
       "      <td>0:00:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0:17:18</td>\n",
       "      <td>0:00:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               0.48         0.35           0.88       0:17:33         0:00:37\n",
       "2               0.21         0.31           0.91       0:17:18         0:00:37"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# A hack to force the column headers to wrap.\n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Display the table.\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4b10cfd-dce8-4f6b-bb06-4abd800a37ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99506348-70d4-4863-85f7-67b7bfc02481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listen up, retards!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create sentence and label lists FROM TESTING DATA\n",
    "\n",
    "\n",
    "sentences_test = list(dict_titles_test.values())\n",
    "#print(sentences)\n",
    "#sentences = sentences[100:420]\n",
    "print(sentences_test[50])\n",
    "# make fake labels for now \n",
    "#labels = [1 for ss in sentences]\n",
    "\n",
    "##### SET SENTENCES_TEST to SENTENCES\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "sentences = sentences_test\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,          # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels_test)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "788ff42d-ae13-42cb-9b3b-2879cccfa830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 2,474 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "    logits = result.logits\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b27a8882-6483-4e4c-9a9f-93f656422af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now determine accuracy \n"
     ]
    }
   ],
   "source": [
    "print(\"Now determine accuracy \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e30eabf2-5917-465c-a131-5c8ebe89ed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly labeled 2295\n"
     ]
    }
   ],
   "source": [
    "label_0 = []\n",
    "label_1 = []\n",
    "label_2 = []\n",
    "correct_label=0\n",
    "pred_list = []\n",
    "tru_list = []\n",
    "\n",
    "for ii, ll in enumerate(predictions):\n",
    "    pred_labels_i = np.argmax(ll, axis=1).flatten()\n",
    "    #print(pred_labels_i)\n",
    "    for ee in pred_labels_i:\n",
    "        pred_list.append(ee)\n",
    "        \n",
    "\n",
    "for ii, ll in enumerate(true_labels):\n",
    "    true_labels_i = ll # np.argmax(ll, axis=1).flatten()\n",
    "    #print(true_labels_i)\n",
    "    for tt in true_labels_i:\n",
    "        tru_list.append(tt)\n",
    "\n",
    "for jj, pp in enumerate(pred_list):\n",
    "    #print(pp)\n",
    "    #print(tru_list[ii])\n",
    "    if pp == tru_list[jj]:\n",
    "        correct_label+=1\n",
    "print(\"Correctly labeled {}\".format(correct_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f24fc19-d3ff-4fe7-a428-465ce39e7fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Fraction Correct 0.9276475343573161\n"
     ]
    }
   ],
   "source": [
    "print(\" Fraction Correct {0}\".format(correct_label/len(input_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e151e66-18ce-4fba-b754-dcf456ea0875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the sentiment for every post and write it out into a text file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec6660a1-4307-44fe-b583-d3a9eed88d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24738\n",
      "gme wars suits strike back. warning for all you fellow autists\n"
     ]
    }
   ],
   "source": [
    "# Create sentence and label lists FROM ALL DATA TO THEN WRITE OUT AND SAVE\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "all_dataloader = DataLoader(\n",
    "            dataset,  # The training samples.\n",
    "            sampler = RandomSampler(dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "sentences_all = list(my_dict_titles_all.values())\n",
    "print(len(sentences_all))\n",
    "#sentences = sentences[100:420]\n",
    "print(sentences_all[50])\n",
    "# make fake labels for now \n",
    "#labels = [1 for ss in sentences]\n",
    "\n",
    "##### SET SENTENCES_TEST to SENTENCES\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "sentences = sentences_all\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,          # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels_all)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eec02a89-4860-4662-958e-82290f39ec7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 24,738 ALL sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} ALL sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    # Telling the model not to compute or store gradients, saving memory and \n",
    "    # speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions.\n",
    "        result = model(b_input_ids, \n",
    "                     token_type_ids=None, \n",
    "                     attention_mask=b_input_mask,\n",
    "                     return_dict=True)\n",
    "\n",
    "    logits = result.logits\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('  DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4641725d-8a2b-40ca-9b5e-272ca3e45474",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = []\n",
    "\n",
    "for ii, ll in enumerate(predictions):\n",
    "    pred_labels_i = np.argmax(ll, axis=1).flatten()\n",
    "    #print(pred_labels_i)\n",
    "    for ee in pred_labels_i:\n",
    "        final_pred.append(ee)\n",
    "\n",
    "f_out = open(\"./src/bert_predictions.txt\",\"w\")\n",
    "for pp in final_pred:\n",
    "    f_out.write(\"{0}\\n\".format(pp))\n",
    "f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877001d4-295a-4baa-85a9-a03a55fecc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch [conda env:root] * (Local)",
   "language": "python",
   "name": "local-conda-root-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
