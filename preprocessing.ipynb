{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import statements go here\n",
    "import numpy as np\n",
    "import emoji\n",
    "import regex\n",
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "from ipynb.fs.full.WordProcessing import get_processed_data, convert_to_dict, get_words\n",
    "from extract_tickers import make_dict_title, get_split_text_from_dict, cross_check_txt_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing functions go here\n",
    "\n",
    "def extract_emojis(input_file):\n",
    "    emoji_list = []\n",
    "    emoji_mat = {}\n",
    "    posts = input_file.readlines()\n",
    "    for line in posts:\n",
    "        post = line[0]\n",
    "        data = regex.findall(r'\\X', post)\n",
    "        for word in data:\n",
    "            if any(char in emoji.EMOJI_DATA for char in word):\n",
    "                if word not in emoji_list:\n",
    "                    emoji_list.append(word)\n",
    "    \n",
    "    for key in emoji_list:\n",
    "        emoji_mat[key] = np.zeros(len(posts)-1)\n",
    "\n",
    "    i = 0\n",
    "    for line in posts:\n",
    "        post = line[0]\n",
    "        data = regex.findall(r'\\X', post)\n",
    "        for word in data:\n",
    "            for char in word:\n",
    "                if emoji_mat.get(char) is not None:\n",
    "                    emoji_mat[char][i] += 1\n",
    "        i += 1\n",
    "    return emoji_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run preprocessing code\n",
    "def preprocess(f_in,to_list=False):\n",
    "    print(\"[preprocess::extract emojis]\")\n",
    "    f = open(f_in, \"r\")\n",
    "    my_dict_emoji = extract_emojis(f)\n",
    "\n",
    "    # open and process\n",
    "    print(\"[preprocess::extract titles and body]\")\n",
    "    data = pd.read_csv(f_in)\n",
    "    processed=get_processed_data(data,as_list=to_list)\n",
    "    my_dict_titles = convert_to_dict(processed,\"title\")\n",
    "    my_dict_body = convert_to_dict(processed,\"body\")\n",
    "    \n",
    "    print(\"[preprocess::complete]\")\n",
    "    return my_dict_emoji, my_dict_titles, my_dict_body, processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_labels_simple(dict_data,pd):\n",
    "    label_markers = [\"buy\",\"sell\",\"hold\"]\n",
    "    ii = 0\n",
    "    dict_labels = collections.OrderedDict()\n",
    "    for kk, post in dict_data.items():\n",
    "        #print(ii)\n",
    "        if isinstance(post, list):\n",
    "            post = \" \".join(post)\n",
    "        l_post=get_words(post)\n",
    "        label_tracker={\"sell\":0, \"hold\":0, \"buy\":0}\n",
    "        for label in label_markers:\n",
    "            label_counter=l_post.count(label)\n",
    "            if label in label_tracker:\n",
    "                label_tracker[label]=label_counter\n",
    "            #if label_counter>0: \n",
    "            #print(\"label {0} appeared {1}\".format(label,label_counter))\n",
    "            #print(post)\n",
    "        #print(label_tracker)\n",
    "        max_key = max(label_tracker, key=label_tracker.get)\n",
    "        if label_tracker[max_key] == 0:\n",
    "            #print(\"No specific mention to buy,hold,or sell --> setting to hold\")\n",
    "            max_key = \"hold\"\n",
    "        #print(max_key)\n",
    "        dict_labels[ii]=max_key\n",
    "        #if ii==400:\n",
    "        #    break    \n",
    "        ii+=1\n",
    "    return dict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# useage sanity check\n",
    "#dict_titles[2345]\n",
    "#dict_body[2345]\n",
    "#for emoji_val in dict_emojis.keys():\n",
    "#        print(emoji_val, np.sum(dict_emojis[emoji_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dict_emojis, dict_titles, dict_body = preprocess('dataset/reddit_wsb.csv')#,to_list=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#my_simple_labels = set_labels_simple(dict_titles,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(my_simple_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
