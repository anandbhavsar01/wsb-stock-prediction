{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import statements go here\n",
    "import numpy as np\n",
    "import emoji\n",
    "import regex\n",
    "import pandas as pd\n",
    "\n",
    "from ipynb.fs.full.WordProcessing import get_processed_data, convert_to_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing functions go here\n",
    "\n",
    "def extract_emojis(input_file):\n",
    "    emoji_list = []\n",
    "    emoji_mat = {}\n",
    "    posts = input_file.readlines()\n",
    "    for line in posts:\n",
    "        post = line[0]\n",
    "        data = regex.findall(r'\\X', post)\n",
    "        for word in data:\n",
    "            if any(char in emoji.EMOJI_DATA for char in word):\n",
    "                if word not in emoji_list:\n",
    "                    emoji_list.append(word)\n",
    "    \n",
    "    for key in emoji_list:\n",
    "        emoji_mat[key] = np.zeros(len(posts)-1)\n",
    "\n",
    "    i = 0\n",
    "    for line in posts:\n",
    "        post = line[0]\n",
    "        data = regex.findall(r'\\X', post)\n",
    "        for word in data:\n",
    "            for char in word:\n",
    "                if emoji_mat.get(char) is not None:\n",
    "                    emoji_mat[char][i] += 1\n",
    "        i += 1\n",
    "    return emoji_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6cc599aa-4d0c-486e-bb23-c297cfd4bf58",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run preprocessing code\n",
    "def preprocess():\n",
    "    f = open('dataset/reddit_wsb.csv', \"r\")\n",
    "    emoji_mat = extract_emojis(f)\n",
    "    for emoji_val in mat.keys():\n",
    "        print(emoji_val, np.sum(mat[emoji_val]))\n",
    "    return emoji_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b667e4-64ef-40c5-9850-1d679cda0d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocess::extract emojis]\n",
      "[preprocess::extract titles and body]\n",
      "[preprocess::complete]\n"
     ]
    }
   ],
   "source": [
    "# Run preprocessing code\n",
    "def preprocess(f_in):\n",
    "    print(\"[preprocess::extract emojis]\")\n",
    "    f = open(f_in, \"r\")\n",
    "    my_dict_emoji = extract_emojis(f)\n",
    "\n",
    "    # open and process\n",
    "    print(\"[preprocess::extract titles and body]\")\n",
    "    data = pd.read_csv(f_in)\n",
    "    processed=get_processed_data(data)\n",
    "    my_dict_titles = convert_to_dict(processed,\"title\")\n",
    "    my_dict_body = convert_to_dict(processed,\"body\")\n",
    "    print(\"[preprocess::complete]\")\n",
    "    return my_dict_emoji, my_dict_titles, my_dict_body\n",
    "    \n",
    "dict_emojis, dict_titles, dict_body = preprocess('dataset/reddit_wsb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sanity check\n",
    "#dict_titles[2345]\n",
    "#dict_body[2345]\n",
    "#for emoji_val in dict_emojis.keys():\n",
    "#        print(emoji_val, np.sum(dict_emojis[emoji_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
